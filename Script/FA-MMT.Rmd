---
title: "FA-MMT"
author: "Jimmy Zhang"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{tspa-interaction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r Loading packages, echo = FALSE, warning = FALSE, message = FALSE}
#Load in libraries
library(psych)
library(tidyverse)
library(dplyr)
library(EFAtools)
library(caret)
library(nortest)
library(ggpubr)
library(nFactors)
library(lavaan)

#Set random seed
set.seed(42)
```

```{r import data, echo = FALSE, warning = FALSE, message = FALSE}
MMT_Meta <- read.csv("/home/gengruiz/FA_LLMBench/Data/MMT_MetaTask.csv")
```

```{r data preprocessing, echo = FALSE, warning = FALSE, message = FALSE}
MMT_Meta$Model <- factor(MMT_Meta$Model)
MMT_Meta <- mutate_if(MMT_Meta,is.character, as.numeric)
write.table(MMT_Meta, file = "colnames.dat", row.names = FALSE, col.names = TRUE, sep = " ")
scaled_Data <- MMT_Meta %>% mutate(across(where(is.numeric), scale))

# This data cannot pass KMO test and Bartlett's sphericity test due to insufficient rank
# Strategy: simulate clustered data
KMO(scaled_Data[,-c(1,2)])
```

```{r generate clustered data, echo = FALSE, warning = FALSE, message = FALSE}
# Remove irrelevant columns
scoreOnly_Data <- scaled_Data[,-1]

# Initialize a list to store the results
random_numbers_list <- list()
cluster_ids <- c()
# Cluster sample size
N = 200

for (i in 1:nrow(scoreOnly_Data)) {
  # Initialize a matrix to store the random numbers for the current row
  row_random_numbers <- matrix(nrow = N, ncol = ncol(scoreOnly_Data))
  
  for (j in 1:ncol(scoreOnly_Data)) {
    random_numbers <- rnorm(N, mean = scoreOnly_Data[i, j], sd = 0.5)
    row_random_numbers[, j] <- random_numbers
  }
  
  random_numbers_list[[i]] <- row_random_numbers
  cluster_ids <- c(cluster_ids, rep(i, N))
}

# Flatten the list and convert to a data frame
flattened_list <- do.call(rbind, random_numbers_list)

# Convert to a data frame
simulated_Data <- as.data.frame(flattened_list)
simulated_Data <- cbind(cluster_id = cluster_ids, simulated_Data)
sample_id <- seq(1, nrow(simulated_Data))
simulated_Data <- cbind(sample_id, simulated_Data)
colnames(simulated_Data) <- c("sample_id", "cluster_id", paste0("V", 1:ncol(scoreOnly_Data)))
# Save the dataframe to a .dat file
write.table(simulated_Data, file = "mefa.dat", row.names = FALSE, col.names = TRUE, sep = " ")

# # Check cluster means 
# row_means_by_cluster <- simulated_Data %>%
#   group_by(cluster_id) %>%
#   summarise(across(starts_with("V"), mean))
# 
# scoreOnly_clustered <- row_means_by_cluster[,-1]
# print(scoreOnly_clustered - scoreOnly_Data)
```

```{r perform MEFA, echo = FALSE, warning = FALSE, message = FALSE}
efa_clustered <- simulated_Data[,-c(1:3)]

# KMO test
KMO(efa_clustered)

# Internal consistency
psych::alpha(efa_clustered)
```

```{r Perform EFA for 32 meta-tasks, echo = FALSE, warning = FALSE, message = FALSE}
N_FACTORS(efa_clustered, criteria = c("PARALLEL", "EKC", "SMT"),
          eigen_type_other = c("SMC", "PCA"))

# Using EFAtools
EFA(efa_clustered, n_factors = 6, rotation = "oblimin", init_comm = "smc", method = "PAF")
EFA(efa_clustered, n_factors = 5, rotation = "oblimin", init_comm = "smc", method = "ULS")
```

```{r Perform EFA for 162 sub-tasks, echo = FALSE, warning = FALSE, message = FALSE}
MMT_Sub <- read.csv("/home/gengruiz/FA_LLMBench/Data/MMT_SubTask.csv")
MMT_Sub$Model <- factor(MMT_Sub$Model)
MMT_Sub <- mutate_if(MMT_Sub,is.character, as.numeric)
scaled_Sub <- MMT_Sub %>% mutate(across(where(is.numeric), scale))

scoreOnly_Sub <- scaled_Sub[,-1]

# Initialize a list to store the results
random_numbers_list <- list()
cluster_ids <- c()
# Cluster sample size
N = 200

for (i in 1:nrow(scoreOnly_Sub)) {
  # Initialize a matrix to store the random numbers for the current row
  row_random_numbers <- matrix(nrow = N, ncol = ncol(scoreOnly_Sub))
  
  for (j in 1:ncol(scoreOnly_Sub)) {
    random_numbers <- rnorm(N, mean = scoreOnly_Sub[i, j], sd = 0.5)
    row_random_numbers[, j] <- random_numbers
  }
  
  random_numbers_list[[i]] <- row_random_numbers
  cluster_ids <- c(cluster_ids, rep(i, N))
}

# Flatten the list and convert to a data frame
flattened_list <- do.call(rbind, random_numbers_list)

# Convert to a data frame
simulated_Sub <- as.data.frame(flattened_list)
simulated_Sub <- cbind(cluster_id = cluster_ids, simulated_Sub)
sample_id <- seq(1, nrow(simulated_Sub))
simulated_Sub <- cbind(sample_id, simulated_Sub)
colnames(simulated_Sub) <- c("sample_id", "cluster_id", paste0("V", 1:ncol(scoreOnly_Sub)))
# Save the dataframe to a .dat file
write.table(simulated_Sub, file = "mefa_sub.dat", row.names = FALSE, col.names = TRUE, sep = " ")

simulated_Sub <- simulated_Sub[,-c(1:2)]
names(simulated_Sub) <- colnames(MMT_Sub[,-1])
KMO(simulated_Sub)
psych::alpha(simulated_Sub)

N_FACTORS(simulated_Sub, criteria = c("PARALLEL", "Hull", "Scree", "SMT", "EKC"),
          eigen_type_other = c("SMC", "PCA"))
```

```{r Test normality, echo = FALSE, warning = FALSE, message = FALSE}
test_normality <- function(data) {
  results <- data.frame(Variable = character(),
                        Skewness = numeric(),
                        Kurtosis = numeric(),
                        JB_statistic = numeric(),
                        JB_p_value = numeric(),
                        stringsAsFactors = FALSE)
  
  for (var in names(data)) {
    if (is.numeric(data[[var]])) {
      # Descriptive Statistics
      skewness_value <- e1071::skewness(data[[var]], na.rm = TRUE)
      kurtosis_value <- e1071::kurtosis(data[[var]], na.rm = TRUE) - 3  # Adjust for excess kurtosis
      
      # Jarque-Bera Test
      jb_test <- tseries::jarque.bera.test(data[[var]])
      
      results <- rbind(results, data.frame(
        Variable = var,
        Skewness = skewness_value,
        Kurtosis = kurtosis_value,
        JB_statistic = jb_test$statistic,
        JB_p_value = jb_test$p.value
      ))
    }
  }
  
  return(results)
}

# Test Normality for All Variables
normality_results <- test_normality(simulated_Sub)
print(round(normality_results[,2:5], 3))
```

```{r Examination Function, echo = FALSE, warning = FALSE, message = FALSE}
# Helper Function 1: Save rotated factor loading
convert_and_save_matrix <- function(input_matrix, file_name = NULL) {
  # Check if input is a matrix
  if (!is.matrix(input_matrix)) {
    stop("Input must be a matrix.")
  }
  new_matrix <- cbind(Variable = rownames(input_matrix), input_matrix)
  rownames(new_matrix) <- NULL
  new_matrix[, -1] <- round(as.numeric(new_matrix[, -1]), 3)
  colnames(new_matrix) <- c("Variable", paste0("F", 1:(ncol(new_matrix) - 1)))
  if (!is.null(file_name)) {
    write.csv(new_matrix, file_name, row.names = FALSE)
    cat("File saved as:", file_name, "\n")
  }
  return(new_matrix)
}

# Helper function 2: Filter out loadings with abs < 0.4
reduced_loadings <- function(input_matrix, threshold = 0.4) {
  data <- as.data.frame(input_matrix)
  data[-1] <- lapply(data[-1], function(x) as.numeric(as.character(x)))
  data <- data %>%
    mutate(across(-1, ~ifelse(abs(.) < threshold, NA, .)))
  return(data)
}

# Helper function 3: Find out variables not loaded onto any factors
find_all_na_variables <- function(data_frame) {
  variables_with_all_NAs <- data_frame %>%
    select(-Variable) %>% 
    apply(1, function(x) all(is.na(x))) %>%
    which()  
  variable_names_with_all_NAs <- data_frame$Variable[variables_with_all_NAs]
  return(variable_names_with_all_NAs)
}

# Helper function 4: Find out variables with negative loadings
find_negative_value_variables <- function(data_frame) {
  variables_with_negatives <- data_frame %>%
    select(-Variable) %>%  
    apply(1, function(x) any(x < 0)) %>%
    which()  
  variable_names_with_negatives <- data_frame$Variable[variables_with_negatives]
  return(variable_names_with_negatives)
}
```

```{r Fit EFA, echo = FALSE, warning = FALSE, message = FALSE}
fit_15 <- EFA(simulated_Sub, n_factors = 15, method = "ML", rotation = "oblimin")
fs_15 <- FACTOR_SCORES(simulated_Sub, fit_15, method = "Bartlett", impute = "none")
#SCREE(simulated_Sub, n_factors = 15, method = "ML", rotation = "oblimin")
fit_ind_15 <- fit_15$fit_indices
rot_load_15 <- fit_15$rot_loadings
new_load_15 <- convert_and_save_matrix(rot_load_15, "rot_load_15.csv")
red_load_15 <- reduced_loadings(as.data.frame(new_load_15))
NAvar_15 <- find_all_na_variables(red_load_15)
Negvar_15 <- find_negative_value_variables(red_load_15)
write.csv(red_load_15, file = "fa_structure_15.csv", row.names = FALSE)
```


```{r Plot model comparison, echo = FALSE, warning = FALSE, message = FALSE}
plot_fit_indices <- function(fit_indices_df) {
  par(mfrow = c(3, 3))  # Arrange plots in a 3x3 grid
  plot(fit_indices_df$Factors, fit_indices_df$rmsea.scaled, type = "b", xlab = "Number of Factors", ylab = "RMSEA (Scaled)", main = "RMSEA (Scaled)")
  plot(fit_indices_df$Factors, fit_indices_df$bic, type = "b", xlab = "Number of Factors", ylab = "BIC", main = "BIC")
  plot(fit_indices_df$Factors, fit_indices_df$cfi.scaled, type = "b", xlab = "Number of Factors", ylab = "CFI (Scaled)", main = "CFI (Scaled)")
  plot(fit_indices_df$Factors, fit_indices_df$tli.scaled, type = "b", xlab = "Number of Factors", ylab = "TLI (Scaled)", main = "TLI (Scaled)")
  plot(fit_indices_df$Factors, fit_indices_df$srmr, type = "b", xlab = "Number of Factors", ylab = "SRMR", main = "SRMR")
  plot(fit_indices_df$Factors, fit_indices_df$chisq.scaled, type = "b", xlab = "Number of Factors", ylab = "Chi-Square (Scaled)", main = "Chi-Square (Scaled)")
  plot(fit_indices_df$Factors, fit_indices_df$df, type = "b", xlab = "Number of Factors", ylab = "Degrees of Freedom", main = "Degrees of Freedom")
  plot(fit_indices_df$Factors, fit_indices_df$pvalue.scaled, type = "b", xlab = "Number of Factors", ylab = "p-value (Scaled)", main = "p-value (Scaled)")
  plot(fit_indices_df$Factors, fit_indices_df$aic, type = "b", xlab = "Number of Factors", ylab = "AIC", main = "AIC")
}

# Plot the fit measures
plot_fit_indices(fit_indices_df)
```










